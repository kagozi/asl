# ============================================================================
# config/modern_config.yaml
# ============================================================================
# Configuration for modern transformer with advanced features

model:
  name: "modern_transformer"
  embedding_dim: 512
  num_q_heads: 8
  num_kv_heads: 4  # Grouped-Query Attention (GQA)
  num_encoder_layers: 6
  num_decoder_layers: 6
  ffn_dim: 1382  # 2.7x embedding_dim for SwiGLU
  dropout: 0.1
  max_seq_len: 512
  activation: "swiglu"
  norm_type: "rms_norm"
  position_encoding: "rope"  # Rotary Position Embeddings
  
  # RoPE-specific settings
  rope_base: 10000
  rope_scaling: null
  
  # Architecture features
  use_gqa: true
  use_rope: true
  use_rms_norm: true
  use_swiglu: true
  pre_norm: true  # Pre-LN architecture

data:
  dataset_name: "achrafothman/aslg_pc12"
  cache_dir: "./data/cache"
  train_size: 82710
  val_size: 4000
  test_size: 4145
  max_length: 100
  
  # Preprocessing
  lowercase_text: true
  uppercase_gloss: true
  remove_punctuation: true
  remove_digits: true

training:
  # Basic settings
  batch_size: 32
  gradient_accumulation_steps: 64  # Effective batch size = 2048
  epochs: 100
  max_steps: null
  
  # Optimization
  optimizer: "adamw"
  learning_rate: 0.0  # Will be calculated by scheduler
  betas: [0.9, 0.98]
  eps: 1.0e-9
  weight_decay: 0.01
  
  # Learning rate schedule
  scheduler: "noam"
  warmup_steps: 4000
  lr_factor: 1.0  # Increased for modern architecture
  
  # Regularization
  label_smoothing: 0.1
  gradient_clip_norm: 1.0
  gradient_clip_value: null
  
  # Mixed precision
  use_amp: true
  amp_dtype: "bfloat16"
  
  # Checkpointing
  save_every_n_epochs: 5
  keep_last_n_checkpoints: 3
  save_best_only: true
  early_stopping_patience: 10

evaluation:
  metrics:
    - "bleu"
    - "meteor"
    - "chrf"
    - "rouge"
  beam_size: 5
  length_penalty: 0.6
  max_generation_length: 100
  num_eval_examples: null

logging:
  log_every_n_steps: 10
  eval_every_n_epochs: 1
  use_tensorboard: true
  use_wandb: false
  wandb_project: "text-gloss-translation"
  wandb_entity: null

compute:
  device: "cuda"
  num_workers: 4
  pin_memory: true
  compile_model: false

seed: 42